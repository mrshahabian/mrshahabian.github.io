---
title: "Efficient Skeleton-based Human Activity Recognition in Ambient Assisted Living Scenarios with Multi-view CNN"
authors: ["Mohamad Reza Shahabian Alashti", "Mohammad Bamorovat Abadi", "Patrick Holthaus", "Catherine Menon", "Farshid Amirabdollahian"]
venue: "BioRob 2024"
year: "2024"
url: "https://ieeexplore.ieee.org/abstract/document/10719939"
videoUrl: "https://youtu.be/-w-f-PhbiDI"
abstract: "Human activity recognition (HAR) plays a critical role in diverse applications and domains, from assessments of ambient assistive living (AAL) settings and the development of smart environments to human-robot interaction (HRI) scenarios. However, using mobile robot cameras in such contexts has limitations like restricted field of view and possible noise. Therefore, employing additional fixed cameras can enhance the field of view and reduce susceptibility to noise. Nevertheless, integrating additional camera perspectives increases complexity, a concern exacerbated by the number of real-time processes that robots should perform in the AAL scenario. This paper introduces our methodology that facilitates the combination of multiple views and compares different aspects of fusing information at low, medium and high levels. Their comparison is guided by parameters such as the number of training parameters, floating-point operations per second (FLOPs), training time, and accuracy. Our findings uncover a paradigm shift, challenging conventional beliefs by demonstrating that simplistic CNN models outperform their more complex counterparts using this innovation. Additionally, the pivotal role of pipeline and data combination emerges as a crucial factor in achieving better accuracy levels. In this study, integrating the additional view with the Robot-view resulted in an accuracy increase of up to 25 %. Ultimately, we have successfully attained a streamlined and efficient multi-view HAR pipeline, which will now be incorporated into AAL interaction scenarios."
---

Official page: [IEEE Xplore](https://ieeexplore.ieee.org/abstract/document/10719939)

Talk video: [YouTube](https://youtu.be/-w-f-PhbiDI)

Published at the 10th IEEE RAS/EMBS International Conference for Biomedical Robotics and Biomechatronics (BioRob).

This work demonstrates how multi-view skeleton data can be effectively processed using convolutional neural networks for real-time activity recognition in smart home environments.

