---
title: "SWAG â€” Soft Wearable Assistive Garment"
description: "AI-driven intent-detection system using multi-sensor biomechanical data for wearable robotics"
tags: ["Deep Learning", "Sensor Fusion", "Meta-Learning", "Transformers", "EMG", "IMU", "Wearable Robotics", "Edge AI"]
year: "2024-Present"
role: "Lead Researcher"
links:
  paper: "https://robotics.herts.ac.uk/"
---

Developing AI-driven intent-detection systems using multi-sensor biomechanical data (EMG, IMU, kinetics, kinematics) with meta-learning and Transformer architectures at the University of Hertfordshire.

## Key Contributions

- **Deep Learning Framework**: Designed and implemented a sensor fusion framework for real-time motion recognition and adaptive human-robot interaction
- **Meta-Learning**: Applied meta-learning techniques for rapid adaptation to new users and movement patterns
- **Transformer Architectures**: Developed attention-based models for temporal pattern recognition in biosignals
- **Dataset Creation**: Led data collection campaigns and created benchmark datasets for wearable sensor research
- **European Collaboration**: Working with partners across Europe on system integration and evaluation

## Technologies

Python, PyTorch, CUDA, ROS2, HRNet, YOLOv7, Meta-Learning, Transformers, Edge AI

## Impact

The project aims to create assistive wearable garments that can predict user intent and provide appropriate assistance for people with mobility impairments, enabling more natural and intuitive human-robot collaboration.

**More info**: [SWAG Project Website](https://robotics.herts.ac.uk/) | [Robotics Research Group, UH](https://robotics.herts.ac.uk/)

