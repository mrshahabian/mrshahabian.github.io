---
title: "Hospital@Home / PRIME Study"
description: "AI-driven virtual ward system for ambient assistive care with multimodal patient monitoring"
tags: ["Healthcare AI", "Multi-View HAR", "HRI", "Sensor Fusion", "Ambient Intelligence", "Deep Learning"]
year: "2024-Present"
role: "Lead AI Researcher"
links:
  paper: "https://robotics.herts.ac.uk/"
---

Developing an AI-driven multimodal pipeline for ambient assistive technology in virtual wards supporting post-surgery and heart failure recovery at the University of Hertfordshire.

## Key Features

- **Multi-View Human Activity Recognition**: Designing advanced HAR systems using multiple camera viewpoints for robust patient monitoring
- **Sensor Fusion Framework**: Integrating multiple sensor modalities for comprehensive health and activity assessment
- **Human-Robot Interaction**: Creating HRI scenarios to enhance patient engagement and provide personalized assistance
- **Adaptive Assistance**: Real-time monitoring and intervention system adapting to patient needs
- **Healthcare Integration**: Bridging healthcare and social care systems

## Collaboration

- Princess Alexandra Hospital
- European research partners
- Funded by Dinwoodie Charitable Company Research Grant (2025-2027)

## Technologies

Python, PyTorch, ROS2, Deep Learning, Sensor Fusion, Multi-View HAR, HRI, Ambient Intelligence, Healthcare AI

## Impact

The system enables patients to recover at home with continuous AI-powered monitoring and robotic assistance, reducing hospital stays while maintaining high-quality care standards.

**More info**: [Robotics Research Group, UH](https://robotics.herts.ac.uk/)

