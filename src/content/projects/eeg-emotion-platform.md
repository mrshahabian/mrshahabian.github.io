---
title: "EEG & Facial Emotion Data Collection Platform"
description: "Web-based platform for synchronized multimodal emotion data collection with EEG and facial recognition"
tags: ["EEG", "Emotion Recognition", "Vision Transformer", "Web Platform", "React", "Node.js", "MUSE 2"]
year: "Feb-Oct 2025"
role: "Lead Developer"
---

Developed a comprehensive web-based platform for synchronised multimodal emotion data collection, integrating EEG (MUSE 2), facial emotion recognition, and human feedback for large-scale emotion studies.

## Key Features

- **Real-Time EEG Streaming**: Integration with MUSE 2 headset for live brainwave data collection
- **Facial Emotion Recognition**: Vision Transformer (ViT) based emotion inference from video
- **Synchronized Data Collection**: Temporal alignment of EEG, facial expressions, and self-reported emotions
- **Large-Scale Study Support**: Designed for 250+ participants studying emotional responses to video content
- **Multi-Dataset Training**: ViT classifiers fine-tuned on FER2013, RAF-DB, AffectNet, and CK+ datasets

## Technologies

Python, JavaScript, React, Node.js, PyTorch, MUSE 2 SDK, Vision Transformer (ViT), FER2013, RAF-DB, AffectNet, CK+

## Technical Highlights

- Web-based architecture for remote participation
- Real-time data streaming and processing
- Robust emotion classification using state-of-the-art ViT models
- Comprehensive data annotation and quality control pipeline
- Secure storage and privacy-preserving data handling

## Applications

The platform enables research in affective computing, emotion AI, and mental health monitoring by providing high-quality multimodal emotion datasets.

